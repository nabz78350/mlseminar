{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from scipy.stats import wasserstein_distance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from qolmat.diffusion_model  import ImputerDiffusion\n",
    "# from qolmat.model import TabDDPM, TsDDPM\n",
    "from diffusion import DDPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import prepare_data, aggregate_market_data\n",
    "from models import CustomTransformerTimeSeries\n",
    "from dataloader import TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_year = \"1999\"\n",
    "end_year = \"2019\"\n",
    "start_year_test = \"2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:00<00:00, 198.52it/s]\n"
     ]
    }
   ],
   "source": [
    "data = aggregate_market_data()\n",
    "\n",
    "df_reindexed, df_orig, df = prepare_data(data, from_year = from_year, start_year_test = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6390, 53])\n"
     ]
    }
   ],
   "source": [
    "train_df = df_reindexed#.loc[:'2019']\n",
    "train_df = train_df.interpolate(method='nearest')\n",
    "X_train = train_df.to_numpy()\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "# diffusion hyperparameters\n",
    "timesteps = 50\n",
    "beta1 = 1e-4\n",
    "beta2 = 0.02\n",
    "\n",
    "# network hyperparameters\n",
    "input_size = 30\n",
    "hidden_dim = 32\n",
    "n_feat = df_reindexed.shape[1] \n",
    "save_dir = './weights/'\n",
    "\n",
    "# training hyperparameters\n",
    "batch_size = 64\n",
    "n_epoch = 50\n",
    "lrate=1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = CustomTransformerTimeSeries(input_size=input_size, n_feat=n_feat, hidden_size=32, num_layers=2, num_heads=2, dropout_prob=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import AutoEncoder, ResidualBlockTS\n",
    "model = AutoEncoder(num_noise_steps = timesteps,\n",
    "                    dim_input = n_feat ,\n",
    "                    residual_block = ResidualBlockTS(hidden_dim, input_size, hidden_dim),\n",
    "                    dim_embedding = hidden_dim,\n",
    "                    dim_output = n_feat,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_qolmat = TsDDPM(num_noise_steps=50,nheads_feature=8,nheads_time=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2022/haocheng.liu/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TimeSeriesDataset(X_train, seq_len=input_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = False)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm = DDPM(model = model, \n",
    "            optimizer = optim,\n",
    "            device = device, \n",
    "            timesteps = timesteps, \n",
    "            beta1 = beta1, \n",
    "            beta2 = beta2, \n",
    "            n_epoch = n_epoch, \n",
    "            batch_size = batch_size, \n",
    "            lrate = lrate, \n",
    "            save_dir = save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 30.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.5688938833773136, MAE: 1.249147517606616, Wasserstein Distance: 1.1463171663819676\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 31.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 31.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 31.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.5048474911600351, MAE: 1.222647676244378, Wasserstein Distance: 1.0544005109949566\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4834148967638612, MAE: 1.2129344809800386, Wasserstein Distance: 1.0409102791946083\n",
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4729015566408634, MAE: 1.207867874763906, Wasserstein Distance: 1.034156420563385\n",
      "epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4605478001758456, MAE: 1.202210757881403, Wasserstein Distance: 1.0204595773255434\n",
      "epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4607879659160972, MAE: 1.2020678939297795, Wasserstein Distance: 1.0215855171060853\n",
      "epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4566257875412703, MAE: 1.200123768299818, Wasserstein Distance: 1.0157927105373703\n",
      "epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4545964989811182, MAE: 1.198956253938377, Wasserstein Distance: 1.0137403271340464\n",
      "epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4506733175367117, MAE: 1.1972105409950018, Wasserstein Distance: 1.0072258933233202\n",
      "epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4519216064363718, MAE: 1.1980370124801993, Wasserstein Distance: 1.0121440924592355\n",
      "epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "losses, maes, wasserstein_distances =ddpm.train(train_loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to DataFrame\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Loss': losses,\n",
    "    'MAE': maes,\n",
    "    'Wasserstein Distance': wasserstein_distances\n",
    "})\n",
    "\n",
    "# Plot metrics\n",
    "metrics_df.plot(subplots=True)\n",
    "plt.xlabel('steps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-DDPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_fddpm import AutoEncoder, ResidualBlockTS\n",
    "# from diffusion import F_DDPM\n",
    "\n",
    "model = AutoEncoder(num_noise_steps = timesteps,\n",
    "                    dim_input = n_feat ,\n",
    "                    residual_block = ResidualBlockTS(hidden_dim, input_size, hidden_dim),\n",
    "                    dim_embedding = hidden_dim,\n",
    "                    dim_output = n_feat ,\n",
    ").to(device)\n",
    "\n",
    "train_dataset = TimeSeriesDataset(X_train, seq_len=input_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = False)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lrate)\n",
    "\n",
    "ddpm = DDPM(model = model, \n",
    "            optimizer = optim,\n",
    "            device = device, \n",
    "            timesteps = timesteps, \n",
    "            beta1 = beta1, \n",
    "            beta2 = beta2, \n",
    "            n_epoch = n_epoch, \n",
    "            batch_size = batch_size, \n",
    "            lrate = lrate, \n",
    "            save_dir = save_dir)\n",
    "\n",
    "losses, maes, wasserstein_distances =ddpm.train(train_loader=train_loader)\n",
    "\n",
    "# Convert lists to DataFrame\n",
    "metrics_fddmp_df = pd.DataFrame({\n",
    "    'Loss': losses,\n",
    "    'MAE': maes,\n",
    "    'Wasserstein Distance': wasserstein_distances\n",
    "})\n",
    "\n",
    "# Plot two models metrics\n",
    "metrics_df.plot(subplots=True)\n",
    "metrics_fddmp_df.plot(subplots=True)\n",
    "plt.xlabel('steps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_plots = len(metrics_df.columns)\n",
    "fig, axes = plt.subplots(nrows=num_plots, ncols=1, figsize=(6, num_plots * 2.5))\n",
    "\n",
    "if num_plots == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, column in enumerate(metrics_df.columns):\n",
    "    metrics_df[column].plot(ax=axes[i], label=f'{column} in t_ddpm')\n",
    "    metrics_fddmp_df[column].plot(ax=axes[i], label=f'{column} in f_ddmp')\n",
    "    axes[i].set_title(column)\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.xlabel('Steps')\n",
    "\n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = X_train.shape[0] // input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_samples, _  = ddpm.sample(n_sample = n_sample, window_size = input_size, dim_input = n_feat, save_rate=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"tabddpm = ImputerDiffusion(\n",
    "    model_qolmat, epochs=n_epoch, batch_size=batch_size, x_valid=df_reindexed, print_valid=True,index_datetime='date',\n",
    "      freq_str = '1B',columnwise=False)\"\"\"\n",
    "#tabddpm.fit(df_reindexed)\n",
    "#pd.DataFrame(tabddpm.model.summary).plot(subplots=True)\n",
    "#plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from evaluation_metrics import TransformerModel\n",
    "from evaluation_metrics import evaluate_synthetic_data\n",
    "path_results = os.getcwd() + \"/results/DDPM/\"\n",
    "# path_results = os.getcwd() + \"\\\\100\\\\\"\n",
    "parameters = [d for d in os.listdir(path_results) if os.path.isdir(os.path.join(path_results, d))]\n",
    "print(parameters)\n",
    "for param in parameters:\n",
    "    print(param)\n",
    "    path_parameters = path_results + param\n",
    "    var = [d for d in os.listdir(path_parameters) if os.path.isdir(os.path.join(path_parameters, d))]\n",
    "    print(var)\n",
    "    train_ratio = 0.8\n",
    "    results = {}\n",
    "    for v in var:\n",
    "        print(v)\n",
    "        config_results = json.load(open(path_parameters + \"/\" + v + '/config.json', 'r'))\n",
    "        #create  samples from df_orig time series\n",
    "        seq_len = config_results[\"SEQ_LEN\"]\n",
    "        n_samples = X_train.shape[0] // seq_len\n",
    "        samples_orig = np.zeros((n_samples, seq_len, n_feat))\n",
    "        for i in range(n_samples):\n",
    "            idx = np.random.randint(0, df_orig.shape[0]-seq_len)\n",
    "            samples_orig[i] = df_orig.iloc[idx:idx+seq_len].values\n",
    "\n",
    "        gen_samples = np.load(path_parameters + \"/\" + v + '/samples.npy')[:n_samples]\n",
    "        eval_model_d = TransformerModel(gen_samples.shape[2], 2, 32, 2, 0.1, task='classification')\n",
    "        eval_model_p = TransformerModel(gen_samples.shape[2], 2, 32, 2, 0.1, task='regression')\n",
    "        eval_results = evaluate_synthetic_data(eval_model_d, eval_model_p, gen_samples, samples_orig, train_ratio=train_ratio)\n",
    "        results[v] = eval_results    \n",
    "    results_df = pd.DataFrame(results).T\n",
    "    results_df.index = results_df.index.astype(float)\n",
    "    results_df = results_df.sort_index()\n",
    "    results_df.index.name = param\n",
    "    results_df.plot(subplots=True, figsize=(10, 8), linewidth=2, marker='o')\n",
    "    plt.xticks(results_df.index)\n",
    "    plt.savefig('./plots/' + param + '_epoch_300_timesteps_100'+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = df_orig['Ret'].unstack().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_data = gen_samples.reshape(-1, gen_samples.shape[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_data = pd.DataFrame(gen_samples[0,:,:].numpy(), index=df_orig[start_year_test:].index[:input_size], columns=df_orig.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_results import plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_orig.columns.tolist()\n",
    "starting_point = df_orig[:end_year].cumsum().dropna().iloc[-1]\n",
    "plot_data(df_orig, synth_data, starting_point, columns[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_metrics import kl_divergence_columns, kl_divergence_rows, wasserstein_distance_columns, wasserstein_distance_rows, compute_frobenius_norm, compute_condition_number, compute_spectral_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data = df_orig[start_year_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_col = kl_divergence_columns(synth_data,true_data)\n",
    "kl_rows = kl_divergence_rows(synth_data,true_data)\n",
    "wasserstein_col = wasserstein_distance_columns(synth_data,true_data)\n",
    "wasserstein_rows = wasserstein_distance_rows(synth_data,true_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_col.mean().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,axes = plt.subplots(nrows=4,ncols = 1,figsize = (15,15))\n",
    "metrics = [kl_col,kl_rows,wasserstein_col, wasserstein_rows]\n",
    "for i,ax in enumerate(axes):\n",
    "    to_plot = metrics[i]\n",
    "    title = to_plot.columns.tolist()[0]\n",
    "    to_plot = to_plot.sort_values(by = title)\n",
    "    if 'rows' in title:\n",
    "        to_plot.plot(ax = axes[i],kind ='line')\n",
    "    else :\n",
    "        to_plot.plot(ax = axes[i],kind ='bar')\n",
    "    axes[i].set_ylabel(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_data.cumsum().sum(1).plot(label = 'total return synthetic data')\n",
    "true_data.cumsum().sum(1).plot(label = 'total return true data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix_true = np.cov(true_data, rowvar=False)\n",
    "cov_matrix_synthetic = np.cov(synthetic_data, rowvar=False)\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "frobenius_norm = compute_frobenius_norm(cov_matrix_true, cov_matrix_synthetic)\n",
    "spectral_norm = compute_spectral_norm(cov_matrix_true, cov_matrix_synthetic)\n",
    "condition_number_true = compute_condition_number(cov_matrix_true)\n",
    "condition_number_synthetic = compute_condition_number(cov_matrix_synthetic)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Frobenius Norm: {frobenius_norm}\")\n",
    "print(f\"Spectral Norm: {spectral_norm}\")\n",
    "print(f\"Condition Number - True Data: {condition_number_true}\")\n",
    "print(f\"Condition Number - Synthetic Data: {condition_number_synthetic}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_results import plot_covariance_matrices, plot_eigenvalues\n",
    "# Plot covariance matrices\n",
    "plot_covariance_matrices(cov_matrix_true, cov_matrix_synthetic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_metrics import eigen_decomposition\n",
    "from plot_results import plot_eigenvalues\n",
    "# Eigenvalue decomposition\n",
    "eigenvalues_true, eigenvectors_true = eigen_decomposition(cov_matrix_true)\n",
    "eigenvalues_synthetic, eigenvectors_synthetic = eigen_decomposition(cov_matrix_synthetic)\n",
    "\n",
    "# Plot eigenvalues\n",
    "plot_eigenvalues(eigenvalues_true, eigenvalues_synthetic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_metrics import compute_principal_components, project_onto_principal_components\n",
    "from plot_results import plot_projection_on_principal_components\n",
    "\n",
    "\n",
    "# Compute principal components from true data\n",
    "_, eigenvectors_true = compute_principal_components(true_data)\n",
    "\n",
    "# Project both true and synthetic data onto these principal components\n",
    "projection_true = project_onto_principal_components(true_data, eigenvectors_true)\n",
    "projection_synthetic = project_onto_principal_components(synth_data, eigenvectors_true)\n",
    "\n",
    "# Visualize the projections\n",
    "plot_projection_on_principal_components(projection_true, projection_synthetic)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
